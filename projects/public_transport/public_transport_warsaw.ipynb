{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"public_transport_warsaw.ipynb","provenance":[],"collapsed_sections":["a-9_-LQZEYrA"]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github","colab_type":"text"},"source":["<a href=\"https://colab.research.google.com/github/ronaldexim/public_transport/blob/master/public_transport_warsaw.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"code","metadata":{"id":"bzE6Ub_JXi3i","colab_type":"code","colab":{}},"source":["!pip install PyDrive"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"S9niZqw5kKJ9","colab_type":"code","colab":{}},"source":["pip install --upgrade tables                                         # potrzebne do wczytania zawartości  plików hdf5 do colaba"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MItTkLqJXopz","colab_type":"code","colab":{}},"source":["from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4rkG8vz9X-46","colab_type":"code","colab":{}},"source":["auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sQOI35_l6MeB","colab_type":"code","colab":{}},"source":["import urllib.request, json, csv, h5py, geopy.distance\n","import pandas as pd\n","import numpy as np\n","import tables as tb\n","from tqdm import tqdm, tqdm_pandas\n","apikey = ''                                                 # apikey do uzyskania pod adresem https://api.um.warszawa.pl/"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"a-9_-LQZEYrA","colab_type":"text"},"source":["# Przygotowanie danych - nie trzeba uruchamiać"]},{"cell_type":"markdown","metadata":{"id":"-WZEwgfD___0","colab_type":"text"},"source":["Przystanki"]},{"cell_type":"code","metadata":{"id":"zztbTGH960qN","colab_type":"code","colab":{}},"source":["api = 'https://api.um.warszawa.pl/api/action/dbstore_get?id=ab75c33d-3a26-4342-b36a-6e5fef0a3ac3&apikey=' + apikey\n","with urllib.request.urlopen(api) as url:\n","    data = json.loads(url.read().decode())['result']\n","    data_list = []\n","    if (data != False):        \n","        for one in data:\n","            row_dict = {}\n","            for col in one['values']:\n","                row_dict[col['key']] = col['value']\n","            data_list.append(row_dict)\n","    else:\n","        print(type(data))\n","        print('API error')\n","stops_columns = ['zespol', 'nazwa_zespolu', 'slupek', 'id_ulicy', 'kierunek', 'dlug_geo', 'szer_geo', 'obowiazuje_od']\n","stops_df = pd.DataFrame(data_list, columns=stops_columns)\n","stops_df.head()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IC8mly5OAbup","colab_type":"text"},"source":["Szuka linii dla przystanków"]},{"cell_type":"code","metadata":{"id":"n_q7J8-b6_Bw","colab_type":"code","colab":{}},"source":["def take_line_str(stop_id, stop_nr):\n","    api = 'https://api.um.warszawa.pl/api/action/dbtimetable_get?id=88cd555f-6f31-43ca-9de4-66c479ad5942' + \\\n","        '&busstopId=' + stop_id + '&busstopNr=' + stop_nr + '&apikey=' + apikey\n","    try:\n","        with urllib.request.urlopen(api) as url:\n","            data = json.loads(url.read().decode())['result']\n","            if (type(data) == str):\n","                raise Exception('API error')\n","            row_str = ''\n","            for one in data:\n","                for col in one['values']:\n","                    row_str = row_str + '|' + col['value']\n","            return row_str\n","    except:\n","        print('error', stop_id, stop_nr)\n","        return ''"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-zSBn29l7Ux6","colab_type":"code","colab":{}},"source":["with open('lines.csv', 'w') as csv_file:\n","    csv_writer = csv.writer(csv_file, delimiter=',')\n","    for index, row in tqdm(stops_df.iterrows(), total=stops_df.shape[0]):\n","        result = [ row['zespol'], row['slupek'], take_line_str(row['zespol'], row['slupek']) ]\n","        csv_writer.writerow(result)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZPtH-9tK7iuM","colab_type":"code","colab":{}},"source":["with open('lines.csv', mode='r') as csv_file:\n","    csv_reader = csv.reader(csv_file)\n","    id_lines_dict = {}\n","    for row in csv_reader:\n","        if row == []: \n","            continue\n","        id_stop = row[0] + '_' + row[1]\n","        if (id_stop in id_lines_dict):\n","            if (id_lines_dict[id_stop] != row[2]):\n","                raise Exception('two or more different values for the key') \n","        else:\n","            id_lines_dict[id_stop] = row[2]\n","\n","for key in id_lines_dict.keys():\n","    id_lines_dict[key] = set(id_lines_dict[key].split('|')[1:])\n","\n","stops_df['id_nu'] = stops_df[ ['zespol', 'slupek'] ].apply(lambda x: x['zespol'] + '_' + x['slupek'], axis=1)            \n","stops_df['line'] = stops_df[ ['id_nu'] ].apply(lambda x: id_lines_dict[ x['id_nu'] ], axis=1)\n","stops_df.head()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dtM-CLjaAzeU","colab_type":"text"},"source":["Feature engineering"]},{"cell_type":"code","metadata":{"id":"kq-FeZh_7l6z","colab_type":"code","colab":{}},"source":["stops_df['changed'] = stops_df.groupby(['id_nu'])['id_nu'].transform('count')                                             # ile było zmian dla przystanku\n","stops_df['no_line'] = stops_df[ ['line'] ].apply(lambda x: len(x['line']) == 0, axis=1)                                   # przystanek bez linii\n","stops_df['error'] = stops_df[ ['dlug_geo', 'szer_geo'] ].apply(lambda x: x['szer_geo'] < '40', axis=1)                    # zamienione długość i szerokość geograficzna"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xv9xJ6BM9Xmy","colab_type":"code","colab":{}},"source":["stops_df[['dlug_geo','szer_geo']] = \\\n","    stops_df[['szer_geo','dlug_geo']].where(stops_df['error'], stops_df[['dlug_geo','szer_geo']].values)                  # zamienia długość i szerokość dla 'error' == True\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"q_Wn_M-68Q8S","colab_type":"code","colab":{}},"source":["stops_df['obowiazuje_od'] = pd.to_datetime(stops_df['obowiazuje_od'])\n","stops_df['last_change'] = stops_df.groupby(['id_nu'])['obowiazuje_od'].transform('max')                                   # data ostatniej zmiany\n","stops_df['actual'] = stops_df[ ['obowiazuje_od', 'last_change'] ].\\\n","    apply(lambda x: x['obowiazuje_od'] == x['last_change'], axis=1)                                                       # aktualna lokalizacja przystanku - po ostatniej zmianie\n","stops_df['deleted'] = stops_df[ ['actual', 'szer_geo'] ].apply(lambda x: x['actual'] & (x['szer_geo'] == 'null'), axis=1) # przystanek skasowany - ostatnia zmiana bez lokalizacji"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"O_o-UviJ8SDc","colab_type":"code","colab":{}},"source":["stops_df['dlug_f'] = pd.to_numeric(stops_df['dlug_geo'], errors='coerce')\n","stops_df['szer_f'] = pd.to_numeric(stops_df['szer_geo'], errors='coerce')\n","stops_df['coord'] = stops_df[ ['dlug_f', 'szer_f'] ].apply(lambda x: (x['szer_f'], x['dlug_f']), axis=1)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OmGxzL72BVZt","colab_type":"text"},"source":["Lista linii"]},{"cell_type":"code","metadata":{"id":"QboYSOgF_Vqc","colab_type":"code","colab":{}},"source":["def find_stops(line):\n","    bool_tab = [line in lines_set for lines_set in stops_df['line'].tolist()]\n","    return (stops_df[bool_tab].query('actual').query('~deleted')['id_nu'].tolist())\n","\n","lines_set = set.union(*stops_df['line'].tolist())\n","lines_df = pd.DataFrame(sorted(list(lines_set)), columns=['line_nr'])\n","lines_df['stops'] = lines_df['line_nr'].map(lambda x: find_stops(x))                     # lista przystanków aktualnych i nie skasowanych dla lini\n","lines_df['stops_nr'] = lines_df['stops'].map(lambda x: len(x))                           # ilość przystanków\n","lines_df.head()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"v1aEeX6bDltj","colab_type":"text"},"source":["Rozkłady"]},{"cell_type":"code","metadata":{"id":"_aGhELlH_g1L","colab_type":"code","colab":{}},"source":["def take_schedule(id_nu, line):\n","    [stop_id, stop_nr] = id_nu.split('_')\n","    api = 'https://api.um.warszawa.pl/api/action/dbtimetable_get?id=e923fa0e-d96c-43f9-ae6e-60518c9f3238' + \\\n","        '&busstopId=' + stop_id + '&busstopNr=' + stop_nr + '&line=' + line + '&apikey=' + apikey\n","    try:\n","        with urllib.request.urlopen(api) as url:\n","            data_list = []\n","            data = json.loads(url.read().decode())['result']\n","            if (type(data) == str):\n","                raise Exception('API error')\n","            for one in data:\n","                row_dict = {}\n","                row_dict['line'] = line\n","                row_dict['id_nu'] = id_nu\n","                for col in one['values']:\n","                    row_dict[col['key']] = col['value']\n","                data_list.append(row_dict)\n","            return data_list\n","    except:\n","        print('error', stop_id, stop_nr, line)\n","        return"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9XXgMudP_0_W","colab_type":"code","colab":{}},"source":["schedule_columns = ['line', 'id_nu', 'brygada', 'kierunek', 'trasa', 'czas', 'symbol_1', 'symbol_2']\n","if 'schedule_df' not in dir():\n","    schedule_df = pd.DataFrame([], columns=schedule_columns)\n","    print('starting new schedule_df')\n","else:\n","    return #schedule done\n","    print('adding to schedule_df')\n","    \n","for index, line in lines_df.iterrows():\n","    for stop in line['stops']:       \n","        print(line['line_nr'], stop)     \n","        one = take_schedule(stop, line['line_nr'])\n","        one_df = pd.DataFrame(one, columns=schedule_columns)\n","        schedule_df = pd.concat([schedule_df, one_df])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"H6h_WhDeEnbX","colab_type":"code","colab":{}},"source":["#stops_df.to_hdf('public_transport_warsaw.h5', key='stops_df_4')\n","#lines_df.to_hdf('public_transport_warsaw.h5', key='lines_df')\n","#schedule_df.to_hdf('public_transport_warsaw2.h5', key='schedule_df')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4QsyScbH-4ST","colab_type":"code","outputId":"42ca93b0-efcb-4994-bb31-b710a9d98a75","colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["with h5py.File('public_transport_warsaw.h5','r') as hf:\n","    dataset_names = list(hf.keys())\n","    print(dataset_names)\n","    \n","with h5py.File('public_transport_warsaw2.h5','r') as hf:\n","    dataset_names = list(hf.keys())\n","    print(dataset_names)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["['lines_df', 'stops_df', 'stops_df_2', 'stops_df_3', 'stops_df_4']\n","['schedule_df']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"NLLGx-l7CXYx","colab_type":"text"},"source":["'stops_df' zawiera ~12k przystanków - tyle miał json za pierwszym razem \n","\n","później było po ~7700 przystanków i to dalej odpytywałem"]},{"cell_type":"markdown","metadata":{"id":"Iw_MNw01EMTc","colab_type":"text"},"source":["# Wczytanie przygotowanych danych z plików"]},{"cell_type":"markdown","metadata":{"id":"keXJMAgauvcF","colab_type":"text"},"source":["Dane jeśli ktoś chce je obrabiać lokalnie\n","\n","https://drive.google.com/drive/folders/1-B3xscQ9NgU-QMWstIpq5NmBKneL3mWI?usp=sharing"]},{"cell_type":"code","metadata":{"id":"W2Sq7FL9ODYG","colab_type":"code","colab":{}},"source":["downloaded = drive.CreateFile({'id': '1FiPQf6rSEtwwKwzAyKoqzMbScSG_jvBF'})\n","downloaded.GetContentFile('lines.csv')\n","downloaded = drive.CreateFile({'id': '1ypIZUgPuor48qKt9ChwY6r3bi-tOf6b2'})\n","downloaded.GetContentFile('public_transport_warsaw.h5')\n","downloaded = drive.CreateFile({'id': '1yvskGIjN-7jY7i3UZ4yck4DZtPagxyYJ'})\n","downloaded.GetContentFile('public_transport_warsaw2.h5')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OL0TpnEXCLt-","colab_type":"code","outputId":"b6f1040a-d614-418e-e886-ca281bdd2040","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["stops_df = pd.read_hdf('public_transport_warsaw.h5', key='stops_df_4', mode='r')\n","lines_df = pd.read_hdf('public_transport_warsaw.h5', key='lines_df', mode='r')\n","schedule_df = pd.read_hdf('public_transport_warsaw2.h5', key='schedule_df', mode='r')\n","print(stops_df.shape, lines_df.shape, schedule_df.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(7727, 19) (345, 3) (918719, 8)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qKHL_rml-ocX","colab_type":"code","colab":{}},"source":["lines_df[lines_df.line_nr == '146']['stops'].tolist()[0]     # przykładowa lista przystanków - ustawienie alfabetyczne a nie wg trasy"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qTdtqSiqI7lo","colab_type":"code","colab":{}},"source":["def dist_id_nu(nr1_id, nr2_id):                                                                             # podaje odległość między przystankami (id)\n","    coord1 = stops_df[stops_df.id_nu == nr1_id].query('actual').query('~deleted')['coord'].tolist()[0]\n","    coord2 = stops_df[stops_df.id_nu == nr2_id].query('actual').query('~deleted')['coord'].tolist()[0]\n","    return geopy.distance.distance(coord1, coord2)\n","\n","def dist_stops(line, nr1, nr2):                                                                             # podaje odległość między przystankami (nr kolejny w liście)\n","    nr1_id = lines_df[lines_df.line_nr == line]['stops'].tolist()[0][nr1]\n","    nr2_id = lines_df[lines_df.line_nr == line]['stops'].tolist()[0][nr2]\n","    return dist_id_nu(nr1_id, nr2_id)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"m8UpyyN_JGbZ","colab_type":"code","colab":{}},"source":["dist_stops('146', 0, 1)"],"execution_count":0,"outputs":[]}]}